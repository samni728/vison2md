import os
import shutil
import tempfile
import uuid
import subprocess
import re
import base64
import requests
import json
from pathlib import Path
from typing import List, Tuple, Optional

from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Query
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

try:
    import fitz  # PyMuPDF
    PYMUPDF_AVAILABLE = True
except ImportError:
    fitz = None
    PYMUPDF_AVAILABLE = False

APP_ROOT = Path(__file__).resolve().parent.parent
UPLOAD_DIR = APP_ROOT / "uploads"
OUTPUT_DIR = APP_ROOT / "outputs"
WEB_DIR = APP_ROOT / "web"
CONFIG_FILE = APP_ROOT / "saved_configs.json"
HISTORY_FILE = APP_ROOT / "history.json"

UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
WEB_DIR.mkdir(parents=True, exist_ok=True)

# å†å²è®°å½•å­˜å–
def load_history() -> List[dict]:
    try:
        if HISTORY_FILE.exists():
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []
    except Exception:
        return []

def save_history(history: List[dict]):
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {str(e)}")

DEFAULT_MODEL_PATH = str(Path.home() / ".cache/lm-studio/models/EZCon/Qwen2.5-VL-7B-Instruct-4bit-mlx")

# é»˜è®¤æç¤ºè¯é€‰é¡¹
DEFAULT_PROMPTS = {
    "describe": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬å›¾ç‰‡ä¸­çš„ä¸»è¦å…ƒç´ ã€é¢œè‰²ã€å¸ƒå±€ç­‰ã€‚",
    "invoice": "è¯·ç”¨ markdown æ ¼å¼è¯¦ç»†æè¿°è¿™å¼ å‘ç¥¨æˆ–æ–‡æ¡£é¡µé¢çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šå‘ç¥¨å·ç ã€æ—¥æœŸã€é‡‘é¢ã€å•†å®¶ä¿¡æ¯ã€å•†å“æ˜ç»†ç­‰ã€‚",
    "pdf_extract": """è¯·ä»”ç»†è¯†åˆ«å¹¶æå–è¿™ä¸ªPDFé¡µé¢çš„æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼ŒæŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¿›è¡Œï¼š

1. **ä¿æŒåŸæ–‡æ ¼å¼**ï¼šä¸¥æ ¼æŒ‰ç…§åŸæ–‡æ¡£çš„æ®µè½ç»“æ„ã€æ ‡é¢˜å±‚çº§ã€åˆ—è¡¨æ ¼å¼ç­‰è¿›è¡Œæ’ç‰ˆ
2. **å®Œæ•´æå–**ï¼šæå–é¡µé¢ä¸Šçš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ­£æ–‡ã€å›¾è¡¨è¯´æ˜ã€é¡µçœ‰é¡µè„šç­‰
3. **ä¿æŒæ’ç‰ˆ**ï¼šä½¿ç”¨é€‚å½“çš„Markdownæ ¼å¼ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼ç­‰ï¼‰æ¥é‡ç°åŸæ–‡æ¡£çš„è§†è§‰æ•ˆæœ
4. **åºå·ä¿ç•™**ï¼šä¿æŒåŸæœ‰çš„ç¼–å·ã€é¡¹ç›®ç¬¦å·ã€å¼•ç”¨æ ¼å¼ç­‰
5. **è¡¨æ ¼å¤„ç†**ï¼šå¦‚æœæ˜¯è¡¨æ ¼ï¼Œè¯·ç”¨Markdownè¡¨æ ¼æ ¼å¼å‘ˆç°
6. **å…¬å¼å¤„ç†**ï¼šå¦‚æœæ˜¯æ•°å­¦å…¬å¼æˆ–ç‰¹æ®Šç¬¦å·ï¼Œè¯·å°½é‡ä¿æŒåŸæ ·æˆ–ä½¿ç”¨é€‚å½“çš„Markdownè¯­æ³•

è¯·ç›´æ¥è¾“å‡ºæå–çš„å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜æ–‡å­—æˆ–è§£é‡Šã€‚""",
    "custom": "è¯·ç”¨ markdown æ ¼å¼è¯¦ç»†æè¿°è¿™å¼ å‘ç¥¨æˆ–æ–‡æ¡£é¡µé¢çš„ä¿¡æ¯ã€‚"
}

DEFAULT_PROMPT = DEFAULT_PROMPTS["invoice"]

app = FastAPI(title="Qwen2.5-VL WebUI", version="0.1.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def run_mlx_vlm_generate(image_path: Path, prompt: str, model_path: str, max_tokens: int, temperature: float) -> str:
    python_exec = os.environ.get("VLM_PYTHON", "python")
    
    # ä½¿ç”¨MLX VLMæ”¯æŒçš„åŸºæœ¬å‚æ•°
    cmd = [
        python_exec, "-m", "mlx_vlm", "generate",
        "--model", model_path,
        "--max-tokens", str(max_tokens),
        "--temperature", str(temperature),
        "--prompt", prompt,
        "--image", str(image_path),
    ]
    
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨
        env = os.environ.copy()
        env["PYTORCH_MPS_HIGH_WATERMARK_RATIO"] = "0.0"  # å‡å°‘å†…å­˜é¢„ç•™
        
        completed = subprocess.run(
            cmd, 
            capture_output=True, 
            text=True, 
            check=True,
            env=env,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        stdout = (completed.stdout or "").strip()
        if not stdout:
            stdout = (completed.stderr or "").strip()
        return stdout
    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=500, detail="æ¨¡å‹è°ƒç”¨è¶…æ—¶ï¼Œå¯èƒ½æ˜¯å†…å­˜ä¸è¶³å¯¼è‡´çš„")
    except subprocess.CalledProcessError as e:
        stderr = (e.stdout or "") + "\n" + (e.stderr or "")
        if "Insufficient Memory" in stderr or "OutOfMemory" in stderr:
            raise HTTPException(status_code=500, detail=f"å†…å­˜ä¸è¶³ï¼Œè¯·å°è¯•å‡å°‘PDFé¡µæ•°æˆ–ä½¿ç”¨APIè°ƒç”¨\né”™è¯¯: {stderr.strip()}")
        else:
            raise HTTPException(status_code=500, detail=f"æ¨¡å‹è°ƒç”¨å¤±è´¥\nå‘½ä»¤: {' '.join(cmd)}\né”™è¯¯: {stderr.strip()}")


def run_api_generate(image_path: Path, prompt: str, base_url: str, api_key: str, model_name: str, max_tokens: int, temperature: float) -> str:
    """é€šè¿‡APIè°ƒç”¨ç”Ÿæˆå†…å®¹"""
    try:
        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
        with open(image_path, "rb") as image_file:
            image_base64 = base64.b64encode(image_file.read()).decode('utf-8')
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        data = {
            "model": model_name,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(
            base_url,
            json=data,
            headers=headers,
            timeout=120
        )
        
        if response.status_code != 200:
            raise HTTPException(
                status_code=500, 
                detail=f"APIè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}"
            )
        
        result = response.json()
        
        # æå–ç”Ÿæˆçš„å†…å®¹
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            return content
        else:
            raise HTTPException(status_code=500, detail="APIå“åº”æ ¼å¼é”™è¯¯")
            
    except requests.RequestException as e:
        raise HTTPException(status_code=500, detail=f"APIè¯·æ±‚å¤±è´¥: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"APIè°ƒç”¨å‡ºé”™: {str(e)}")


def load_saved_configs() -> dict:
    """åŠ è½½ä¿å­˜çš„é…ç½®"""
    try:
        if CONFIG_FILE.exists():
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"models": [], "prompts": []}
    except Exception:
        return {"models": [], "prompts": []}

def save_configs(configs: dict):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶ - Dockerå®¹å™¨å…¼å®¹ç‰ˆæœ¬"""
    import os
    import tempfile
    import shutil
    import time
    
    max_retries = 3
    retry_delay = 0.5  # seconds
    
    for attempt in range(max_retries):
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆé…ç½®å†…å®¹
            config_content = json.dumps(configs, ensure_ascii=False, indent=2)
            
            # æ–¹æ³•1ï¼šç›´æ¥å†™å…¥ï¼ˆæœ€å¿«æœ€ç®€å•ï¼‰
            try:
                with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
                    f.write(config_content)
                    f.flush()
                    os.fsync(f.fileno())
                
                # éªŒè¯å†™å…¥æˆåŠŸ
                with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                    loaded_data = json.load(f)
                    if loaded_data == configs:  # éªŒè¯æ•°æ®ä¸€è‡´æ€§
                        return  # æˆåŠŸäº†
                    else:
                        raise Exception("æ•°æ®éªŒè¯å¤±è´¥")
                        
            except (OSError, IOError) as e:
                if "Device or resource busy" in str(e):
                    if attempt >= max_retries - 1:
                        raise Exception("æ–‡ä»¶è¢«æŒç»­é”å®šï¼Œéœ€è¦æ£€æŸ¥å…¶ä»–è¿›ç¨‹æ˜¯å¦åœ¨è®¿é—®é…ç½®æ–‡ä»¶")
                    time.sleep(retry_delay * (2 ** attempt))
                    continue
                else:
                    raise e
            
            except:
                # æ–‡ä»¶éªŒè¯å¤±è´¥ï¼Œç”¨ä¸´æ—¶æ–‡ä»¶æ–¹æ³•
                pass
            
            # æ–¹æ³•2ï¼šä¸´æ—¶æ–‡ä»¶åŸå­æ€§æ›¿æ¢ï¼ˆç”¨äºè§£å†³å¹¶å‘å’Œé”å®šé—®é¢˜ï¼‰
            import tempfile
            with tempfile.NamedTemporaryFile(
                mode='w+', 
                encoding='utf-8', 
                suffix='.tmp',
                dir='/tmp',  # åœ¨ç³»ç»Ÿä¸´æ—¶ç›®å½•ï¼Œé¿å…Dockeræ–‡ä»¶é”å®š
                delete=False
            ) as tmp_file:
                tmp_file.write(config_content)
                tmp_file.flush()
                os.fsync(tmp_file.fileno())
                temp_name = tmp_file.name
            
            # ç”¨shell mvå®ç°åŸå­æ€§æ›¿æ¢
            import subprocess
            try:
                subprocess.run(['mv', temp_name, str(CONFIG_FILE)], 
                             check=True, capture_output=True)
            except (subprocess.CalledProcessError, FileNotFoundError):
                # å¦‚æœmvä¸å¯ç”¨ï¼Œä½¿ç”¨python shutil
                shutil.move(temp_name, CONFIG_FILE)
            
            # æœ€ç»ˆéªŒè¯æ–‡ä»¶å†™å…¥
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                if json.load(f) == configs:
                    return
                else:
                    raise Exception("æ–‡ä»¶éªŒè¯å¤±è´¥")
                    
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
                continue
            else:
                # ç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º
                error_msg = str(e)
                if "Device or resource busy" in error_msg:
                    error_msg = "é…ç½®è¢«é”å®š - è¯·ç­‰å¾…å…¶ä»–æ“ä½œå®Œæˆåå†è¯•"
                elif "Permission denied" in error_msg:
                    error_msg = "æƒé™ä¸è¶³ - æ£€æŸ¥Dockeræ–‡ä»¶æŒ‚è½½æƒé™"
                elif "read-only" in error_msg.lower():
                    error_msg = "é…ç½®ç›®å½•åªè¯» - æ£€æŸ¥Dockerå·æƒé™è®¾ç½®"
                    
                raise HTTPException(status_code=500, detail=f"æ— æ³•ä¿å­˜é…ç½®: {error_msg}")

def clean_output_text(raw: str) -> str:
    # é¦–å…ˆç§»é™¤æ€è€ƒè¿‡ç¨‹å†…å®¹ï¼ˆ<think>æ ‡ç­¾å†…çš„æ‰€æœ‰å†…å®¹ï¼‰
    # å¤„ç†å®Œæ•´çš„thinkæ ‡ç­¾
    text = re.sub(r'<think>.*?</think>', '', raw, flags=re.DOTALL | re.IGNORECASE)
    # å¤„ç†ä¸å®Œæ•´çš„thinkæ ‡ç­¾ï¼ˆæ²¡æœ‰ç»“æŸæ ‡ç­¾çš„æƒ…å†µï¼‰
    text = re.sub(r'<think>.*$', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # å»é™¤å¸¸è§å™ªå£°ï¼ˆPrompt/ç»Ÿè®¡/åˆ†éš”ç¬¦ç­‰ï¼‰
    lines = text.splitlines()
    cleaned: List[str] = []
    skip_next = False
    
    for i, line in enumerate(lines):
        L = line.strip()
        
        # è·³è¿‡ç©ºè¡Œ
        if not L:
            cleaned.append(line)
            continue
            
        # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯å’Œç‰¹æ®Šæ ‡è®°
        if (L == "==========" or
            L.startswith("Prompt:") or
            L.startswith("Generation:") or
            L.startswith("Peak memory:") or
            L.startswith("You are a helpful assistant") or
            L.startswith("<|im_start|>") or
            L.startswith("<|im_end|>") or
            L.startswith("<|vision_start|>") or
            L.startswith("<|vision_end|>") or
            L.startswith("<|image_pad|>") or
            L.startswith("Files:") or  # ç§»é™¤æ–‡ä»¶è·¯å¾„ä¿¡æ¯
            "è¯·è¯†åˆ« pdf" in L or  # ç§»é™¤æç¤ºè¯å†…å®¹
            "ç¬¬" in L and "é¡µçš„å†…å®¹å¦‚ä¸‹" in L):  # ç§»é™¤é¡µé¢è¯´æ˜
            continue
            
        # è·³è¿‡åŒ…å«æç¤ºè¯çš„å®Œæ•´è¡Œ
        if any(phrase in L for phrase in [
            "è¯·è¯†åˆ« pdf", "æ ¹æ® pdf", "åŸæ¥çš„æ ¼å¼", "markdown æ ¼å¼",
            "ç”Ÿæˆå¯¹åº”é¡µæ•°", "md æ–‡æ¡£", "è¯·æ³¨æ„ï¼Œç”±äºåŸæ–‡æ¡£å†…å®¹è¾ƒé•¿"
        ]):
            continue
            
        # ç§»é™¤ä»£ç å—æ ‡è®°ï¼ˆå¦‚æœä¸æ˜¯çœŸæ­£çš„ä»£ç å†…å®¹ï¼‰
        if L.startswith("```markdown") or L.startswith("```"):
            # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„ä»£ç å—å†…å®¹
            if i > 0 and "ç¬¬" in lines[i-1] and "é¡µçš„å†…å®¹å¦‚ä¸‹" in lines[i-1]:
                continue
            cleaned.append(line)
            continue
            
        # ç§»é™¤æ–‡ä»¶è·¯å¾„å’Œä¸´æ—¶ä¿¡æ¯
        if ("/var/folders/" in L or 
            "/tmp/" in L or 
            "pdf_pages_" in L or
            ".png" in L and "Files:" in L):
            continue
            
        cleaned.append(line)
    
    # å‹ç¼©å°¾éƒ¨å¤šä½™ç©ºè¡Œ
    text = "\n".join(cleaned)
    text = re.sub(r"\n{3,}", "\n\n", text).strip()
    
    # ç§»é™¤å¼€å¤´çš„æ— ç”¨æ–‡æœ¬
    text = re.sub(r'^.*?```markdown\s*', '', text, flags=re.DOTALL)
    text = re.sub(r'^.*?ç¬¬.*?é¡µçš„å†…å®¹å¦‚ä¸‹ï¼š\s*', '', text, flags=re.DOTALL)
    
    return text


def save_markdown(md_text: str, base_name: str) -> Path:
    safe_name = base_name
    for ch in ['\\', '/', ':', '*', '?', '"', '<', '>', '|']:
        safe_name = safe_name.replace(ch, '_')
    out_path = OUTPUT_DIR / f"{safe_name}.md"
    out_path.write_text(md_text, encoding="utf-8")
    return out_path


def process_single_image(image_path: Path, prompt: str, model_path: str, max_tokens: int, temperature: float, out_base_name: str, base_url: Optional[str] = None, api_key: Optional[str] = None, model_name: Optional[str] = None, original_file_url: Optional[str] = None) -> Tuple[Path, str]:
    if base_url and api_key and model_name:
        # ä½¿ç”¨APIè°ƒç”¨
        md_raw = run_api_generate(image_path, prompt, base_url, api_key, model_name, max_tokens, temperature)
    else:
        # ä½¿ç”¨æœ¬åœ°MLXæ¨¡å‹
        md_raw = run_mlx_vlm_generate(image_path, prompt, model_path, max_tokens, temperature)
    
    md_clean = clean_output_text(md_raw)
    if original_file_url:
        header = f"[åŸå§‹æ–‡ä»¶]({original_file_url})\n\n"
        md_to_save = header + md_clean
    else:
        md_to_save = md_clean
    out_path = save_markdown(md_to_save, out_base_name)
    return out_path, md_to_save


def process_pdf_with_progress(pdf_path: Path, prompt: str, model_path: str, max_tokens: int, temperature: float, out_base_name: str, max_pages: int = 10, base_url: Optional[str] = None, api_key: Optional[str] = None, model_name: Optional[str] = None, progress_callback=None, original_file_url: Optional[str] = None) -> Tuple[Path, str]:
    if not PYMUPDF_AVAILABLE:
        raise HTTPException(status_code=500, detail="PyMuPDFæœªå®‰è£…ï¼Œæ— æ³•å¤„ç†PDFæ–‡ä»¶ã€‚è¯·è¿è¡Œ: pip install PyMuPDF")
    
    doc = fitz.open(pdf_path)
    tmp_dir = Path(tempfile.mkdtemp(prefix="pdf_pages_"))
    
    total_pdf_pages = len(doc)
    
    try:
        all_results: List[str] = []
        
        # è®¡ç®—éœ€è¦å¤„ç†çš„æ‰¹æ¬¡æ•°é‡
        if total_pdf_pages <= max_pages:
            # å¦‚æœæ€»é¡µæ•°å°äºç­‰äºæœ€å¤§é¡µæ•°ï¼Œä¸€æ¬¡æ€§å¤„ç†
            batches = [(0, total_pdf_pages)]
        else:
            # å¦‚æœæ€»é¡µæ•°å¤§äºæœ€å¤§é¡µæ•°ï¼Œåˆ†æ‰¹å¤„ç†
            batches = []
            for start in range(0, total_pdf_pages, max_pages):
                end = min(start + max_pages, total_pdf_pages)
                batches.append((start, end))
        
        for batch_idx, (start_page, end_page) in enumerate(batches):
            batch_results: List[str] = []
            
            # æ·»åŠ æ‰¹æ¬¡æ ‡é¢˜
            if len(batches) > 1:
                batch_results.append(f"## æ‰¹æ¬¡ {batch_idx + 1}/{len(batches)} (ç¬¬ {start_page + 1}-{end_page} é¡µ)\n")
            
            for page_index in range(start_page, end_page):
                # æ›´æ–°è¿›åº¦
                if progress_callback:
                    progress = int((page_index / total_pdf_pages) * 100)
                    progress_callback(f"æ­£åœ¨å¤„ç†ç¬¬ {page_index + 1}/{total_pdf_pages} é¡µ", progress)
                page = doc.load_page(page_index)
                
                # é™ä½DPIä»¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼šä»180é™åˆ°120
                pix = page.get_pixmap(dpi=120)
                img_path = tmp_dir / f"page_{page_index + 1}.png"
                pix.save(str(img_path))
                
                # é‡Šæ”¾é¡µé¢å†…å­˜
                pix = None
                page = None

                page_prompt = f"ç¬¬ {page_index + 1} é¡µï¼š\n\n" + prompt
                
                try:
                    if base_url and api_key and model_name:
                        # ä½¿ç”¨APIè°ƒç”¨
                        md_raw = run_api_generate(img_path, page_prompt, base_url, api_key, model_name, max_tokens, temperature)
                    else:
                        # ä½¿ç”¨æœ¬åœ°MLXæ¨¡å‹
                        md_raw = run_mlx_vlm_generate(img_path, page_prompt, model_path, max_tokens, temperature)
                    
                    md_clean = clean_output_text(md_raw)
                    batch_results.append(f"## ç¬¬ {page_index + 1} é¡µ\n\n" + md_clean + "\n\n---\n")
                    
                    # åˆ é™¤ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶ä»¥é‡Šæ”¾ç£ç›˜ç©ºé—´
                    img_path.unlink(missing_ok=True)
                    
                except Exception as e:
                    error_msg = f"å¤„ç†ç¬¬ {page_index + 1} é¡µæ—¶å‡ºé”™: {str(e)}"
                    batch_results.append(f"## ç¬¬ {page_index + 1} é¡µ\n\nâŒ {error_msg}\n\n---\n")
                    img_path.unlink(missing_ok=True)
                    continue
            
            all_results.extend(batch_results)
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ‰¹æ¬¡ï¼Œæ·»åŠ åˆ†éš”ç¬¦
            if batch_idx < len(batches) - 1:
                all_results.append("\n---\n")

        # æ·»åŠ å¤„ç†æ‘˜è¦å’Œåˆ†é¡µç»“æ„
        header_link = f"[åŸå§‹æ–‡ä»¶]({original_file_url})\n\n" if original_file_url else ""
        summary = header_link + f"# æ–‡æ¡£è§£æï¼š{pdf_path.name}\n\n"
        summary += f"**å¤„ç†æ‘˜è¦**: å…± {total_pdf_pages} é¡µï¼Œåˆ† {len(batches)} ä¸ªæ‰¹æ¬¡å¤„ç†\n\n"
        
        # æ·»åŠ ç›®å½•ç»“æ„
        summary += "## ğŸ“‹ æ–‡æ¡£ç›®å½•\n\n"
        for i in range(1, total_pdf_pages + 1):
            summary += f"- [ç¬¬ {i} é¡µ](#ç¬¬-{i}-é¡µ)\n"
        summary += "\n---\n\n"
        
        merged_md = summary + "\n".join(all_results)
        out_path = save_markdown(merged_md, out_base_name)
        return out_path, merged_md
        
    finally:
        # ç¡®ä¿æ¸…ç†èµ„æº
        doc.close()
        shutil.rmtree(tmp_dir, ignore_errors=True)


@app.post("/api/process")
async def process_files(
    files: List[UploadFile] = File(..., description="æ”¯æŒå¤šæ–‡ä»¶ï¼šPDF æˆ– å›¾ç‰‡"),
    prompt_type: str = Form("invoice", description="æç¤ºè¯ç±»å‹: describe, invoice, custom"),
    custom_prompt: str = Form("", description="è‡ªå®šä¹‰æç¤ºè¯"),
    model_path: str = Form(DEFAULT_MODEL_PATH, description="MLXæ¨¡å‹è·¯å¾„"),
    base_url: str = Form("", description="APIåŸºç¡€URL"),
    api_key: str = Form("", description="APIå¯†é’¥"),
    model_name: str = Form("", description="APIæ¨¡å‹åç§°"),
    max_tokens: int = Form(1024),
    temperature: float = Form(0.0),
    max_pages: int = Form(10, description="PDFæœ€å¤§å¤„ç†é¡µæ•°"),
    batch_size: int = Form(5, description="å›¾ç‰‡æ‰¹æ¬¡å¤„ç†æ•°é‡"),
    merge_output: bool = Form(False, description="æ˜¯å¦åˆå¹¶æ‰€æœ‰è¾“å‡ºåˆ°å•ä¸ªæ–‡æ¡£"),
):
    if not files:
        raise HTTPException(status_code=400, detail="æœªæ¥æ”¶åˆ°æ–‡ä»¶")

    # ç¡®å®šä½¿ç”¨çš„æç¤ºè¯
    if prompt_type == "custom" and custom_prompt:
        final_prompt = custom_prompt
    elif prompt_type in DEFAULT_PROMPTS:
        final_prompt = DEFAULT_PROMPTS[prompt_type]
    else:
        final_prompt = DEFAULT_PROMPT

    # ç¡®å®šä½¿ç”¨APIè¿˜æ˜¯æœ¬åœ°æ¨¡å‹
    use_api = bool(base_url and api_key and model_name)
    
    # åˆ†ç¦»PDFå’Œå›¾ç‰‡æ–‡ä»¶
    pdf_files = []
    image_files = []
    
    for uf in files:
        suffix = Path(uf.filename).suffix.lower()
        if suffix == ".pdf":
            pdf_files.append(uf)
        elif suffix in [".png", ".jpg", ".jpeg", ".webp", ".bmp", ".tiff"]:
            image_files.append(uf)
        else:
            raise HTTPException(status_code=415, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {suffix}")
    
    results = []
    
    # å¤„ç†PDFæ–‡ä»¶ï¼ˆå•ä¸ªå¤„ç†ï¼Œå†…éƒ¨å¯èƒ½åˆ†æ‰¹ï¼‰
    for uf in pdf_files:
        suffix = Path(uf.filename).suffix.lower()
        temp_name = f"{uuid.uuid4().hex}{suffix}"
        temp_path = UPLOAD_DIR / temp_name
        with temp_path.open("wb") as w:
            content = await uf.read()
            w.write(content)

        # ä¿å­˜åŸå§‹æ–‡ä»¶å‰¯æœ¬ï¼ˆä»¥åŸå§‹æ–‡ä»¶åæŒä¹…åŒ–ï¼‰
        original_saved_path = UPLOAD_DIR / uf.filename
        try:
            with original_saved_path.open("wb") as ow:
                ow.write(content)
        except Exception:
            original_saved_path = temp_path

        base_name = Path(uf.filename).stem

        try:
            out_path, md_clean = process_pdf_with_progress(
                temp_path, final_prompt, model_path, max_tokens, temperature, base_name, max_pages,
                base_url if use_api else None, api_key if use_api else None, model_name if use_api else None,
                None,
                original_file_url=f"/uploads/{Path(original_saved_path).name}"
            )
        finally:
            try:
                temp_path.unlink(missing_ok=True)
            except Exception:
                pass

        results.append({
            "input": uf.filename,
            "output_markdown": f"/outputs/{Path(out_path).name}",
            "saved_path": str(out_path),
            "markdown": md_clean,
            "original_file": uf.filename,
            "original_file_url": f"/uploads/{Path(original_saved_path).name}",
            "original_saved_path": str(original_saved_path),
        })

        # å†™å…¥å†å²è®°å½•
        history = load_history()
        history.append({
            "id": uuid.uuid4().hex,
            "input": uf.filename,
            "output_markdown": f"/outputs/{Path(out_path).name}",
            "original_file_url": f"/uploads/{Path(original_saved_path).name}",
            "timestamp": int(__import__('time').time())
        })
        save_history(history)
    
    # å¤„ç†å›¾ç‰‡æ–‡ä»¶ï¼ˆæ‰¹æ¬¡å¤„ç†ï¼‰
    if image_files:
        # å°†å›¾ç‰‡åˆ†æ‰¹å¤„ç†
        image_batches = []
        for i in range(0, len(image_files), batch_size):
            batch = image_files[i:i + batch_size]
            image_batches.append(batch)
        
        for batch_idx, batch in enumerate(image_batches):
            batch_results = []
            
            for uf in batch:
                suffix = Path(uf.filename).suffix.lower()
                temp_name = f"{uuid.uuid4().hex}{suffix}"
                temp_path = UPLOAD_DIR / temp_name
                with temp_path.open("wb") as w:
                    content = await uf.read()
                    w.write(content)
                # ä¿å­˜åŸå§‹æ–‡ä»¶å‰¯æœ¬
                original_saved_path = UPLOAD_DIR / uf.filename
                try:
                    with original_saved_path.open("wb") as ow:
                        ow.write(content)
                except Exception:
                    original_saved_path = temp_path

                base_name = Path(uf.filename).stem

                try:
                    out_path, md_clean = process_single_image(
                        temp_path, final_prompt, model_path, max_tokens, temperature, base_name,
                        base_url if use_api else None, api_key if use_api else None, model_name if use_api else None,
                        original_file_url=f"/uploads/{Path(original_saved_path).name}"
                    )
                    
                    batch_results.append({
                        "input": uf.filename,
                        "output_markdown": f"/outputs/{Path(out_path).name}",
                        "saved_path": str(out_path),
                        "markdown": md_clean,
                        "original_file": uf.filename,
                        "original_file_url": f"/uploads/{Path(original_saved_path).name}",
                        "original_saved_path": str(original_saved_path),
                    })

                    # å†™å…¥å†å²è®°å½•
                    history = load_history()
                    history.append({
                        "id": uuid.uuid4().hex,
                        "input": uf.filename,
                        "output_markdown": f"/outputs/{Path(out_path).name}",
                        "original_file_url": f"/uploads/{Path(original_saved_path).name}",
                        "timestamp": int(__import__('time').time())
                    })
                    save_history(history)
                finally:
                    try:
                        temp_path.unlink(missing_ok=True)
                    except Exception:
                        pass
            
            # å¦‚æœæœ‰å¤šä¸ªæ‰¹æ¬¡ï¼Œæ·»åŠ æ‰¹æ¬¡æ ‡é¢˜
            if len(image_batches) > 1:
                for result in batch_results:
                    result["markdown"] = f"## å›¾ç‰‡æ‰¹æ¬¡ {batch_idx + 1}/{len(image_batches)}\n\n{result['markdown']}"
            
            results.extend(batch_results)

    # å¦‚æœéœ€è¦åˆå¹¶è¾“å‡ºï¼Œåˆ›å»ºå•ä¸ªåˆå¹¶æ–‡æ¡£
    if merge_output and results:
        merged_content = []
        merged_content.append("# åˆå¹¶æ–‡æ¡£å¤„ç†ç»“æœ\n\n")
        merged_content.append(f"å¤„ç†æ—¶é—´ï¼š{__import__('time').strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        merged_content.append(f"å¤„ç†æ–‡æ¡£æ•°é‡ï¼š{len(results)} ä¸ª\n\n")
        merged_content.append("---\n\n")
        
        # ä¸ºæ¯ä¸ªæ–‡æ¡£åˆ›å»ºä¸€ä¸ªæ¸…æ™°çš„ç« èŠ‚
        for idx, result in enumerate(results, 1):
            # è·å–åŸå§‹æ–‡ä»¶åï¼ˆå®Œæ•´æ–‡ä»¶åï¼‰
            original_filename = result.get('original_file', f'document_{idx}')
            filename_with_ext = Path(original_filename).stem
            upload_url = result.get('original_file_url', '')
            
            # æ·»åŠ æ–‡æ¡£åˆ†éš”æ ‡é¢˜
            merged_content.append(f"# {idx}. {filename_with_ext}\n\n")
            
            # æ·»åŠ åŸå§‹æ–‡ä»¶ä¿¡æ¯
            if upload_url:
                merged_content.append(f"**åŸå§‹æ–‡ä»¶ï¼š** [{original_filename}]({upload_url})\n\n")
            else:
                merged_content.append(f"**åŸå§‹æ–‡ä»¶ï¼š** {original_filename}\n\n")
            
            # æ·»åŠ å¤„ç†ç»“æœ
            content = result.get('markdown', '')
            if content:
                merged_content.append(content)
            
            # æ·»åŠ æ–‡æ¡£é—´åˆ†éš”
            if idx < len(results):  # ä¸è¦åœ¨æœ€åä¸€ä¸ªæ–‡æ¡£åæ·»åŠ åˆ†éš”
                merged_content.append("\n\n---\n\n")
        
        # ä¿å­˜åˆå¹¶æ–‡æ¡£
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        merged_filename = f"åˆå¹¶æ–‡æ¡£_{timestamp}"
        merged_path = save_markdown("".join(merged_content), merged_filename)
        
        # åˆ›å»ºæ–°çš„ç»“æœï¼ŒåŒ…å«åˆå¹¶ä¿¡æ¯
        merged_result = {
            "input": f"åˆå¹¶å¤„ç† ({len(results)}ä¸ªæ–‡æ¡£)",
            "output_markdown": f"/outputs/{Path(merged_path).name}",
            "saved_path": str(merged_path),
            "markdown": "".join(merged_content),
            "original_file": f"åˆå¹¶æ–‡æ¡£_{timestamp}",
            "original_file_url": "",
            "merged_count": len(results),
            "merged_original_files": [r.get('original_file', '') for r in results]
        }
        
        results = [merged_result]

    return JSONResponse({"ok": True, "results": results})


@app.get("/api/prompts")
async def get_prompts():
    """è·å–å¯ç”¨çš„é»˜è®¤æç¤ºè¯"""
    return JSONResponse({
        "ok": True,
        "prompts": DEFAULT_PROMPTS
    })


@app.get("/api/saved-configs")
async def get_saved_configs():
    """è·å–ä¿å­˜çš„é…ç½®"""
    configs = load_saved_configs()
    return JSONResponse({
        "ok": True,
        "configs": configs
    })


@app.post("/api/save-config")
async def save_config(
    config_type: str = Form(..., description="é…ç½®ç±»å‹: model æˆ– prompt"),
    name: str = Form(..., description="é…ç½®åç§°"),
    model_type: str = Form("", description="æ¨¡å‹ç±»å‹: local æˆ– api"),
    model_path: str = Form("", description="MLXæ¨¡å‹è·¯å¾„"),
    base_url: str = Form("", description="APIåŸºç¡€URL"),
    api_key: str = Form("", description="APIå¯†é’¥"),
    model_name: str = Form("", description="APIæ¨¡å‹åç§°"),
    prompt_content: str = Form("", description="è‡ªå®šä¹‰æç¤ºè¯å†…å®¹")
):
    """ä¿å­˜é…ç½®"""
    configs = load_saved_configs()
    
    if config_type == "model":
        # ä¿å­˜æ¨¡å‹é…ç½®
        model_config = {
            "id": str(uuid.uuid4()),
            "name": name,
            "model_type": model_type,
            "model_path": model_path,
            "base_url": base_url,
            "api_key": api_key,
            "model_name": model_name,
            "created_at": str(Path().cwd())
        }
        configs["models"].append(model_config)
    elif config_type == "prompt":
        # ä¿å­˜è‡ªå®šä¹‰æç¤ºè¯
        prompt_config = {
            "id": str(uuid.uuid4()),
            "name": name,
            "content": prompt_content,
            "created_at": str(Path().cwd())
        }
        configs["prompts"].append(prompt_config)
    else:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„é…ç½®ç±»å‹")
    
    save_configs(configs)
    
    return JSONResponse({
        "ok": True,
        "message": "é…ç½®ä¿å­˜æˆåŠŸ",
        "config_id": model_config.get("id") if config_type == "model" else prompt_config.get("id")
    })


@app.delete("/api/delete-config")
async def delete_config(
    config_type: str = Form(..., description="é…ç½®ç±»å‹: model æˆ– prompt"),
    config_id: str = Form(..., description="é…ç½®ID")
):
    """åˆ é™¤é…ç½®"""
    configs = load_saved_configs()
    
    if config_type == "model":
        # åˆ é™¤æ¨¡å‹é…ç½®
        configs["models"] = [m for m in configs["models"] if m["id"] != config_id]
    elif config_type == "prompt":
        # åˆ é™¤æç¤ºè¯é…ç½®
        configs["prompts"] = [p for p in configs["prompts"] if p["id"] != config_id]
    else:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„é…ç½®ç±»å‹")
    
    save_configs(configs)
    
    return JSONResponse({
        "ok": True,
        "message": "é…ç½®åˆ é™¤æˆåŠŸ"
    })


@app.post("/api/process_stream")
async def process_files_stream(
    files: List[UploadFile] = File(..., description="æ”¯æŒå¤šæ–‡ä»¶ï¼šPDF æˆ– å›¾ç‰‡"),
    prompt_type: str = Form("invoice", description="æç¤ºè¯ç±»å‹: describe, invoice, custom"),
    custom_prompt: str = Form("", description="è‡ªå®šä¹‰æç¤ºè¯"),
    model_path: str = Form(DEFAULT_MODEL_PATH, description="MLXæ¨¡å‹è·¯å¾„"),
    base_url: str = Form("", description="APIåŸºç¡€URL"),
    api_key: str = Form("", description="APIå¯†é’¥"),
    model_name: str = Form("", description="APIæ¨¡å‹åç§°"),
    max_tokens: int = Form(1024),
    temperature: float = Form(0.0),
    max_pages: int = Form(10, description="PDFæœ€å¤§å¤„ç†é¡µæ•°"),
):
    """æµå¼å¤„ç†æ–‡ä»¶ï¼Œæ”¯æŒè¿›åº¦æ›´æ–°"""
    if not files:
        raise HTTPException(status_code=400, detail="æœªæ¥æ”¶åˆ°æ–‡ä»¶")

    # ç¡®å®šä½¿ç”¨çš„æç¤ºè¯
    if prompt_type == "custom" and custom_prompt:
        final_prompt = custom_prompt
    elif prompt_type in DEFAULT_PROMPTS:
        final_prompt = DEFAULT_PROMPTS[prompt_type]
    else:
        final_prompt = DEFAULT_PROMPT

    # ç¡®å®šä½¿ç”¨APIè¿˜æ˜¯æœ¬åœ°æ¨¡å‹
    use_api = bool(base_url and api_key and model_name)
    
    async def generate_progress():
        results = []
        for file_idx, uf in enumerate(files):
            # å‘é€æ–‡ä»¶å¼€å§‹å¤„ç†çš„æ¶ˆæ¯
            yield f"data: {json.dumps({'type': 'file_start', 'file': uf.filename, 'file_index': file_idx})}\n\n"
            
            suffix = Path(uf.filename).suffix.lower()
            temp_name = f"{uuid.uuid4().hex}{suffix}"
            temp_path = UPLOAD_DIR / temp_name
            
            # å…ˆè¯»å–æ–‡ä»¶å†…å®¹ï¼Œç„¶åå†™å…¥ä¸´æ—¶æ–‡ä»¶
            content = await uf.read()
            with temp_path.open("wb") as w:
                w.write(content)

            base_name = Path(uf.filename).stem

            try:
                def progress_callback(message, progress):
                    # è¿™é‡Œå¯ä»¥å‘é€è¿›åº¦æ›´æ–°ï¼Œä½†ç”±äºæ˜¯åŒæ­¥å‡½æ•°ï¼Œæš‚æ—¶è·³è¿‡
                    pass
                
                if suffix in [".png", ".jpg", ".jpeg", ".webp", ".bmp", ".tiff"]:
                    out_path, md_clean = process_single_image(
                        temp_path, final_prompt, model_path, max_tokens, temperature, base_name,
                        base_url if use_api else None, api_key if use_api else None, model_name if use_api else None
                    )
                elif suffix == ".pdf":
                    out_path, md_clean = process_pdf_with_progress(
                        temp_path, final_prompt, model_path, max_tokens, temperature, base_name, max_pages,
                        base_url if use_api else None, api_key if use_api else None, model_name if use_api else None,
                        progress_callback
                    )
                else:
                    raise HTTPException(status_code=415, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {suffix}")
                
                result = {
                    "input": uf.filename,
                    "output_markdown": f"/outputs/{Path(out_path).name}",
                    "saved_path": str(out_path),
                    "markdown": md_clean,
                }
                results.append(result)
                
                # å‘é€æ–‡ä»¶å¤„ç†å®Œæˆçš„æ¶ˆæ¯
                yield f"data: {json.dumps({'type': 'file_complete', 'file': uf.filename, 'result': result})}\n\n"
                
            except Exception as e:
                error_result = {
                    "input": uf.filename,
                    "error": str(e)
                }
                results.append(error_result)
                yield f"data: {json.dumps({'type': 'file_error', 'file': uf.filename, 'error': str(e)})}\n\n"
            finally:
                try:
                    temp_path.unlink(missing_ok=True)
                except Exception:
                    pass
        
        # å‘é€æœ€ç»ˆç»“æœ
        yield f"data: {json.dumps({'type': 'complete', 'results': results})}\n\n"
    
    return StreamingResponse(generate_progress(), media_type="text/plain")


# å†å²è®°å½•æ¥å£
@app.get("/api/history")
async def get_history():
    return JSONResponse({
        "ok": True,
        "history": load_history()
    })


@app.delete("/api/history")
async def delete_history_record(record_id: str = Query(...)):
    history = load_history()
    new_history = [h for h in history if h.get("id") != record_id]
    save_history(new_history)
    return JSONResponse({"ok": True})


app.mount("/outputs", StaticFiles(directory=str(OUTPUT_DIR)), name="outputs")
app.mount("/uploads", StaticFiles(directory=str(UPLOAD_DIR)), name="uploads")
app.mount("/", StaticFiles(directory=str(WEB_DIR), html=True), name="web")
