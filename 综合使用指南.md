# Vision AI 批量处理工具 综合使用指南

## 📖 目录

1. [功能概述](#功能概述)
2. [快速开始](#快速开始)
3. [模型配置](#模型配置)
4. [提示词选择](#提示词选择)
5. [智能内容过滤](#智能内容过滤)
6. [输出格式](#输出格式)
7. [技术特性](#技术特性)
8. [常见问题](#常见问题)
9. [更新日志](#更新日志)

---

## 🚀 功能概述

Vision AI 批量处理工具是一个强大的文档处理工具，支持两种模型配置方式和多种提示词选项，让您更灵活地处理图片和 PDF 文档。

### ✨ 核心功能

- 🎯 **双模型支持**：本地 MLX 模型 + API 调用
- 📄 **PDF 专用提取**：专门的 PDF 文档识别提示词
- 🧠 **智能过滤**：自动移除思考过程和噪声内容
- 📊 **实时进度**：进度条显示处理状态
- 🎨 **现代界面**：美观易用的 Web 界面

---

## 🏃‍♂️ 快速开始

### 方法一：Docker 部署（推荐）

```bash
# 1. 克隆项目
git clone <项目地址>
cd vision-ai-webui

# 2. 启动服务
docker-compose up -d

# 3. 访问应用
# 浏览器打开：http://localhost:8000
```

**查看状态和日志：**

```bash
# 查看服务状态
docker-compose ps

# 查看日志
docker-compose logs -f

# 停止服务
docker-compose down
```

### 方法二：本地部署

#### 1. 启动服务器

**使用脚本启动（推荐）**

```bash
# 进入项目目录
cd /Users/samni/Desktop/开发项目/qwen2.5vl_webui

# 启动服务器（固定端口8000）
./scripts/serve.sh
```

**直接启动**

```bash
cd /Users/samni/Desktop/开发项目/qwen2.5vl_webui
uvicorn server.main:app --host 0.0.0.0 --port 8000 --reload
```

### 2. 访问界面

服务器启动后，打开浏览器访问：**`http://localhost:8000`**

### 3. 端口配置

- **默认端口**：8000（固定端口，不再变化）
- **端口冲突解决**：
  - 停止占用进程：`lsof -ti:8000 | xargs kill -9`
  - 使用其他端口：`PORT=8001 ./scripts/serve.sh`
  - 查看占用进程：`lsof -i:8000`

### 4. 停止服务器

在终端中按 `Ctrl+C` 停止服务器。

### 5. 基本使用流程

1. **选择模型配置方式**（本地 MLX 模型 或 API 调用）
2. **配置模型参数**（可保存配置供下次使用）
3. **选择提示词类型**（可保存自定义提示词）
4. **调整处理参数**
5. **上传文件**（支持拖拽）
6. **开始处理**并查看实时进度
7. **下载结果**（Markdown 格式）

### 6. 配置保存功能

#### 💾 **保存模型配置**

**本地 MLX 模型配置**：

1. 选择"本地 MLX 模型"
2. 输入模型路径
3. 点击"💾 保存本地模型配置"按钮
4. 输入配置名称

**API 模型配置**：

1. 选择"API 调用"
2. 输入 API 基础 URL、API 密钥、模型名称
3. 点击"💾 保存模型配置"按钮
4. 输入配置名称

#### 📝 **保存自定义提示词**

1. 选择"自定义提示词"
2. 输入提示词内容
3. 点击"💾 保存提示词"按钮
4. 输入提示词名称

#### 🔧 **配置管理**

在"配置管理"区域，您可以：

- **查看保存的配置**：所有保存的模型配置和自定义提示词
- **一键加载配置**：点击"加载"按钮快速应用保存的配置
- **删除配置**：点击"删除"按钮移除不需要的配置

**配置管理界面特点**：

- 📋 **分类显示**：模型配置和提示词分别显示
- ⚡ **快速加载**：一键应用保存的配置
- 🗑️ **便捷删除**：确认后删除不需要的配置
- 💾 **持久保存**：配置保存在本地文件中

### 7. 智能 UI 优化

#### 🎯 **动态参数显示**

系统会根据您选择的文件类型智能显示相关参数：

**PDF 文件处理**：

- 显示"PDF 最大处理页数"参数
- 用于控制 PDF 内部页面的分批处理
- 防止处理大型 PDF 时内存溢出

**图片文件处理**：

- 显示"图片批次处理数量"参数
- 用于批量处理多个图片文件
- 提升图片处理效率

**混合文件处理**：

- 同时显示两个参数
- 分别优化 PDF 和图片的处理策略

#### ⚡ **自动文件类型检测**

- **拖放检测**：拖放文件后自动识别文件类型
- **UI 更新**：根据文件类型动态显示/隐藏相关参数
- **智能提示**：只显示当前需要的配置选项

#### 🔄 **处理逻辑优化**

| 文件类型     | 显示参数         | 处理方式         | 优化目的     |
| ------------ | ---------------- | ---------------- | ------------ |
| **PDF 文件** | PDF 最大处理页数 | 内部页数分批处理 | 防止内存溢出 |
| **图片文件** | 图片批次处理数量 | 多个图片批次处理 | 提升处理效率 |
| **混合文件** | 两个参数都显示   | 分别按策略处理   | 灵活处理组合 |

#### 💡 **使用场景示例**

**场景 1：只处理 PDF 文档**

```
操作：拖放PDF文件
显示：PDF最大处理页数参数
好处：界面简洁，专注PDF处理
```

**场景 2：只处理图片文件**

```
操作：拖放图片文件
显示：图片批次处理数量参数
好处：批量处理图片，提升效率
```

**场景 3：混合处理**

```
操作：同时拖放PDF和图片
显示：两个参数都显示
好处：灵活处理不同文件类型
```

**场景 4：无文件时**

```
操作：清空文件列表
显示：隐藏所有处理参数
好处：界面整洁，避免混淆
```

### 8. 界面折叠优化

#### 🎨 **折叠功能特点**

系统提供了智能的折叠功能，让界面更加美观和简洁：

**模型配置区域**：

- 位于顶部，默认展开状态，方便用户配置模型参数
- 配置完成后可以折叠，减少界面占用空间
- 点击标题栏即可折叠/展开

**配置管理区域**：

- 位于模型配置区域下方，默认折叠状态，保持界面简洁
- 需要管理配置时点击展开
- 配置完成后可以重新折叠
- 与模型配置区域在同一表单区域内，操作更连贯

#### ⚡ **折叠操作方式**

| 区域         | 默认状态 | 操作方式              | 图标变化 |
| ------------ | -------- | --------------------- | -------- |
| **模型配置** | 展开     | 点击"🔧 模型配置"标题 | ▼ ↔ ▶    |
| **配置管理** | 折叠     | 点击"💾 配置管理"标题 | ▶ ↔ ▼    |

#### 💡 **使用场景**

**场景 1：初次使用**

```
1. 模型配置区域展开 → 配置模型参数
2. 配置管理区域折叠 → 保持界面简洁
3. 配置完成后折叠模型配置 → 专注文件处理
```

**场景 2：管理保存的配置**

```
1. 点击展开配置管理区域
2. 查看、加载或删除保存的配置
3. 操作完成后重新折叠
```

**场景 3：日常使用**

```
1. 模型配置折叠 → 减少界面干扰
2. 配置管理折叠 → 保持界面简洁
3. 专注文件拖放和处理
```

#### 🎯 **界面优化效果**

- **更美观**：折叠后界面更简洁，视觉焦点更集中
- **更高效**：配置完成后可折叠，减少界面占用
- **更直观**：通过图标清楚显示折叠/展开状态
- **更灵活**：根据需要随时展开/折叠不同区域

---

## 🔧 模型配置

### 📱 本地 MLX 模型

**适用场景**：有本地 Qwen2.5-VL MLX 模型的情况

**配置方法**：

- 在"MLX 模型路径"中输入模型文件路径
- 例如：`/Users/.../Qwen2.5-VL-7B-Instruct-4bit-mlx`

**优势**：

- ✅ 无需网络连接
- ✅ 数据隐私保护
- ✅ 无 API 调用费用

### 🌐 API 调用

**适用场景**：使用云端模型服务

**配置参数**：

- **API 基础 URL**：`https://api.openai.com/v1/chat/completions`
- **API 密钥**：`sk-...`（您的 API 密钥）
- **模型名称**：`gpt-4-vision-preview`

**优势**：

- ✅ 无需本地模型
- ✅ 支持更多模型选择
- ✅ 处理能力更强

---

## 📝 提示词选择

### 🎯 PDF 文本提取（推荐用于 PDF 文档）

**适用场景**：学术论文、技术文档、报告、专利等 PDF 文档

**核心特点**：

- 🎯 **精确提取**：专门针对 PDF 文档设计，提取准确率高
- 📐 **格式保持**：严格保持原文档的排版和结构
- 🔢 **序号保留**：保持编号、列表、引用等格式
- 📊 **表格处理**：智能识别并转换为 Markdown 表格
- 🧮 **公式支持**：处理数学公式和特殊符号
- 📝 **完整内容**：提取页面上所有文字，包括页眉页脚
- 🚫 **无噪声**：直接输出内容，不添加解释说明

**提示词内容**：

```
请仔细识别并提取这个PDF页面的所有文本内容，按照以下要求进行：

1. **保持原文格式**：严格按照原文档的段落结构、标题层级、列表格式等进行排版
2. **完整提取**：提取页面上的所有文字内容，包括标题、正文、图表说明、页眉页脚等
3. **保持排版**：使用适当的Markdown格式（标题、列表、表格等）来重现原文档的视觉效果
4. **序号保留**：保持原有的编号、项目符号、引用格式等
5. **表格处理**：如果是表格，请用Markdown表格格式呈现
6. **公式处理**：如果是数学公式或特殊符号，请尽量保持原样或使用适当的Markdown语法

请直接输出提取的内容，不要添加任何说明文字或解释。
```

### 📋 其他提示词选项

| 提示词类型       | 适用场景               | 说明                         |
| ---------------- | ---------------------- | ---------------------------- |
| **发票信息提取** | 发票、收据等结构化文档 | 提取结构化信息，便于数据处理 |
| **描述图片内容** | 图片、截图等视觉内容   | 描述图片中的视觉元素         |
| **自定义提示词** | 特殊需求               | 根据具体需求编写专门的提示词 |

### 💡 使用建议

| 文档类型      | 推荐提示词                    | 说明                             |
| ------------- | ----------------------------- | -------------------------------- |
| 学术论文 PDF  | PDF 文本提取（保持原格式）    | 保持论文的结构、公式、引用格式等 |
| 技术文档 PDF  | PDF 文本提取（保持原格式）    | 保持代码块、表格、列表等格式     |
| 专利文档 PDF  | PDF 文本提取（保持原格式）    | 保持专利的编号、权利要求等格式   |
| 报告文档 PDF  | PDF 文本提取（保持原格式）    | 保持报告的章节、图表等结构       |
| 发票/收据 PDF | 发票信息提取（Markdown 格式） | 提取结构化信息，便于数据处理     |
| 图片/截图     | 描述图片内容                  | 描述图片中的视觉元素             |
| 特殊需求      | 自定义提示词                  | 根据具体需求编写专门的提示词     |

---

## 🧠 智能内容过滤

系统会自动过滤模型输出中的以下内容，确保输出纯净：

### 🎯 过滤内容

- **思考过程**：自动移除 `<think>` 标签内的所有思考内容
- **系统消息**：移除文件路径、提示词、系统提示等信息
- **噪声内容**：清理临时文件信息、处理说明等
- **格式标记**：移除不必要的代码块标记和分隔符

### 📝 支持的思考格式

1. **标准格式**：`<think>思考内容</think>`
2. **大小写混合**：`<Think>思考内容</Think>`
3. **多行思考**：支持跨行的思考内容
4. **多个思考块**：自动处理文档中的多个思考段落

### 📊 过滤效果示例

**过滤前**：

```
<think>我需要分析这张图片...</think>### 发明内容：[0006] 本发明...
```

**过滤后**：

```
### 发明内容：[0006] 本发明...
```

### 🔧 技术实现

**过滤算法**：

```python
# 处理完整的think标签
text = re.sub(r'<think>.*?</think>', '', raw, flags=re.DOTALL | re.IGNORECASE)
# 处理不完整的think标签（没有结束标签的情况）
text = re.sub(r'<think>.*$', '', text, flags=re.DOTALL | re.IGNORECASE)
```

**处理流程**：

1. **识别阶段**：扫描文档中的所有 `<think>` 标签
2. **移除阶段**：使用正则表达式完全移除思考内容
3. **清理阶段**：继续执行其他内容清理算法
4. **输出阶段**：输出纯净的文档内容

---

## 📄 输出格式

生成的 Markdown 文件具有以下特点：

### 📋 文档结构

- **文档标题**：显示原始文件名
- **处理摘要**：显示总页数和批次信息
- **目录导航**：可点击的页面链接，快速跳转

### 📄 分页格式

- **独立分节**：每页作为独立的二级标题
- **清晰分隔**：页面间用分隔线区分
- **保持结构**：维持 PDF 的原始分页逻辑

### 📝 示例格式

```markdown
# 文档解析：example.pdf

**处理摘要**: 共 7 页，分 1 个批次处理

## 📋 文档目录

- [第 1 页](#第-1-页)
- [第 2 页](#第-2-页)
- [第 3 页](#第-3-页)
  ...

---

## 第 1 页

[页面内容...]

---

## 第 2 页

[页面内容...]
```

---

## ⚙️ 技术特性

### 🔧 后端改进

- 支持 API 调用和本地 MLX 模型两种方式
- 智能参数处理和错误处理
- 新增提示词 API 端点
- 改进的 PDF 处理逻辑
- 智能内容清理算法
- 实时进度反馈

### 🎨 前端改进

- 动态界面切换
- 实时提示词预览
- 现代化进度条设计
- 错误信息高亮显示
- 响应式设计

### 🔄 兼容性

- 向后兼容原有的 MLX 模型配置
- 支持多种 API 接口格式
- 优雅的错误处理
- 跨平台支持

---

## ❓ 常见问题

### Q: PyMuPDF 安装失败怎么办？

**A**: 如果遇到 PyMuPDF 导入错误，应用会显示友好的错误信息。可以尝试：

```bash
pip install --upgrade PyMuPDF
```

### Q: API 调用失败怎么办？

**A**: 检查以下项目：

- API 地址是否正确
- API 密钥是否有效
- 模型名称是否正确
- API 服务是否可用且有足够的配额

### Q: 遇到内存不足错误怎么办？

**A**: 这是 MLX 模型处理大图片时的常见问题，可以通过以下方式解决：

- **减少批次大小**：减少 PDF 最大处理页数
  - 8GB 内存：建议 5 页/批次
  - 16GB 内存：建议 10 页/批次
  - 32GB 内存：建议 20 页/批次
- **使用 API 调用**：替代本地 MLX 模型
- **确保系统内存**：确保系统有足够的可用内存
- **分批处理**：大文档会自动分批处理

### Q: PDF 处理页数限制是多少？

**A**: 这是**批次大小**，不是总页数限制。大文档会自动分批处理：

- **批次大小**：默认 10 页/批次
- **自动分批**：超过批次大小的文档会自动分批处理
- **示例**：30 页 PDF，设置 5 页/批次 = 自动分 6 个批次处理所有 30 页

### Q: 本地模型路径如何配置？

**A**: 输入完整的模型文件夹路径，例如：

```
/Users/username/.cache/lm-studio/models/EZCon/Qwen2.5-VL-7B-Instruct-4bit-mlx
```

### Q: 如何处理带思考功能的模型？

**A**: 系统会自动过滤思考内容：

- **自动识别**：识别 `<think>` 标签内的思考内容
- **完全移除**：彻底清除所有思考过程
- **格式兼容**：支持多种思考格式
- **零配置**：无需任何设置，自动生效

---

## 📚 更新日志

### v2.8.0 (最新)

- ✅ **Docker 容器化支持**
- ✅ **一键部署**（docker-compose 快速启动）
- ✅ **环境隔离**（避免依赖冲突）
- ✅ **跨平台兼容**（支持 Linux、macOS、Windows）
- ✅ **生产就绪**（包含健康检查和数据持久化）

### v2.7.2

- ✅ **优化界面布局**
- ✅ **配置管理移到模型配置下方**（更符合操作逻辑）
- ✅ **界面层次更清晰**（相关功能集中在一起）
- ✅ **用户体验提升**（操作流程更顺畅）

### v2.7.1

- ✅ **修复 think 标签过滤 bug**
- ✅ **处理不完整的 think 标签**（没有结束标签的情况）
- ✅ **完善过滤算法**（确保所有思考内容都被正确移除）
- ✅ **提升输出质量**（文档内容更纯净，无干扰信息）

### v2.7.0

- ✅ **界面折叠优化**
- ✅ **配置区域可折叠**（模型配置和配置管理支持折叠/展开）
- ✅ **项目名称更新**（Vision AI 批量处理工具，更准确反映功能）
- ✅ **界面更美观**（折叠后界面更简洁，专注核心功能）
- ✅ **用户体验提升**（配置好后可折叠，减少界面干扰）

### v2.6.0

- ✅ **智能 UI 优化**
- ✅ **根据文件类型动态显示参数**（PDF 显示页数设置，图片显示批次设置）
- ✅ **图片批次处理功能**（支持批量处理多个图片，提升效率）
- ✅ **自动文件类型检测**（拖放文件后自动识别并更新 UI）
- ✅ **分离处理逻辑**（PDF 和图片采用不同的处理策略）

### v2.5.0

- ✅ **新增配置保存功能**
- ✅ **支持保存模型配置**（本地 MLX 模型和 API 配置）
- ✅ **支持保存自定义提示词**
- ✅ **配置管理界面**（加载、删除保存的配置）
- ✅ **一键加载保存的配置**

### v2.4.0

- ✅ **新增思考内容过滤功能**
- ✅ **自动移除模型输出中的 `<think>` 标签内容**
- ✅ **支持多种思考格式**（大小写混合、多行等）
- ✅ **优化内容清理算法**，确保输出纯净

### v2.3.0

- ✅ **新增专门的 PDF 文本提取提示词**
- ✅ **优化内容清理算法**，去除更多噪声
- ✅ **添加实时进度条显示**
- ✅ **支持流式响应和进度更新**
- ✅ **改进错误处理和用户反馈**

### v2.2.0

- ✅ **修复 MLX VLM 参数兼容性问题**
- ✅ **改进 Markdown 输出格式**
- ✅ **保持 PDF 原始分页结构**
- ✅ **添加可点击的目录导航**
- ✅ **优化页面分隔和格式**

### v2.1.0

- ✅ **修复内存不足问题**
- ✅ **优化 PDF 处理逻辑**
- ✅ **添加页面处理限制**
- ✅ **降低图片 DPI 以减少内存使用**
- ✅ **添加 MLX 模型内存优化参数**
- ✅ **改进错误处理和超时保护**

### v2.0.0

- ✅ **新增 API 调用支持**
- ✅ **添加默认提示词选项**
- ✅ **改进用户界面**
- ✅ **增强错误处理**
- ✅ **添加提示词预览功能**

---

## 🎉 总结

Vision AI 批量处理工具为您提供了：

1. **🎯 专业工具**：专门优化的 PDF 文档处理能力
2. **🧠 智能过滤**：自动清理思考过程和噪声内容
3. **📊 实时反馈**：进度条和状态显示
4. **🎨 现代界面**：美观易用的 Web 界面
5. **⚡ 高效处理**：支持批量处理和多种模型
6. **🔄 灵活配置**：本地模型和 API 调用双重支持

**立即开始使用**：

1. 启动服务器：`./scripts/serve.sh`
2. 访问界面：`http://localhost:8000`
3. 选择提示词：**PDF 文本提取（保持原格式）**
4. 上传文件并开始处理！

**享受使用 Vision AI 批量处理工具！** 🚀

---

_本文档整合了所有功能说明、使用指南和技术特性，为您提供完整的 Vision AI 批量处理工具使用体验。_
